{
    "generation": "import java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.Random;\n// Added missing imports/assuming these interfaces/classes exist\n// import org.apache.commons.math.stat.clustering.Clusterable;\n// import org.apache.commons.math.stat.clustering.Cluster;\n\n    /**\n     * Use K-means++ to choose the initial centers.\n     *\n     * @param <T> type of the points to cluster\n     * @param points the points to choose the initial centers from\n     * @param k the number of centers to choose\n     * @param random random generator to use\n     * @return the initial centers\n     */\n    private static <T extends Clusterable<T>> List<Cluster<T>>\n        chooseInitialCenters(final Collection<T> points, final int k, final Random random) {\n\n        // Convert to list for indexed access. Make a copy to avoid modifying the original collection.\n        final List<T> pointSet = new ArrayList<T>(points);\n        final List<Cluster<T>> resultSet = new ArrayList<Cluster<T>>();\n\n        // Check for empty input or k=0\n        if (points.isEmpty() || k <= 0) {\n            return resultSet;\n        }\n\n        // Choose one center uniformly at random from among the data points.\n        final int firstPointIndex = random.nextInt(pointSet.size());\n        final T firstPoint = pointSet.remove(firstPointIndex);\n        resultSet.add(new Cluster<T>(firstPoint));\n\n        // Array to store the squared distances D(x)^2 for the current iteration\n        double[] dx2 = null;\n\n        while (resultSet.size() < k) {\n            // If no points remain, cannot choose more centers. This might happen\n            // if k is larger than the number of unique points.\n            if (pointSet.isEmpty()) {\n                // Log.warn(String.format(\"Not enough unique points to choose %d centers.\", k)); // If logger available\n                break;\n            }\n\n            // Initialize/resize dx2 for the current number of remaining points\n            dx2 = new double[pointSet.size()];\n\n            // For each data point x, compute D(x)^2, the squared distance between x and\n            // the nearest center that has already been chosen.\n            double sum = 0;\n            for (int i = 0; i < pointSet.size(); i++) {\n                final T p = pointSet.get(i);\n                // Find the nearest cluster (and its center) already chosen\n                final Cluster<T> nearest = getNearestCluster(resultSet, p);\n                // This should not happen if resultSet is not empty (which it isn't after first point)\n                if (nearest == null) {\n                     throw new IllegalStateException(\"Internal error: nearest cluster should not be null during K-means++ initialization\");\n                }\n                final double d = p.distanceFrom(nearest.getCenter());\n                final double dSquared = d * d;\n                dx2[i] = dSquared; // Store the individual squared distance for point i\n                sum += dSquared;   // Add it to the total sum of squared distances\n            }\n\n            // Add one new data point as a center. Each point x is chosen with\n            // probability proportional to D(x)^2.\n\n            int nextCenterIndex;\n            // Handle the case where sum is zero (implies all remaining points are duplicates of existing centers)\n            if (sum == 0) {\n                 // All remaining points have distance 0 to the nearest center.\n                 // K-means++ doesn't strictly define this, but choosing the first point\n                 // is a reasonable strategy and consistent with the weighted selection when r=0.\n                 nextCenterIndex = 0; // Requires pointSet to be non-empty, checked above.\n            } else {\n                // Perform weighted selection:\n                // Draw a random number r in [0, sum)\n                final double r = random.nextDouble() * sum;\n                double cumulativeSum = 0.0;\n                nextCenterIndex = -1; // Initialize, should be overwritten in the loop\n\n                // Iterate through points, accumulating squared distances\n                for (int i = 0; i < dx2.length; i++) {\n                    cumulativeSum += dx2[i];\n                    // If the cumulative sum reaches or exceeds the random threshold r, choose this point\n                    if (cumulativeSum >= r) {\n                        nextCenterIndex = i;\n                        break;\n                    }\n                }\n\n                // Edge case: Due to floating-point inaccuracies, cumulativeSum might end up\n                // slightly less than sum, and r might be very close to sum (or theoretically equal if random.nextDouble() returned 1.0, though unlikely).\n                // If the loop completes without finding an index (should be rare),\n                // it implies r was effectively >= sum, so we should select the last point.\n                if (nextCenterIndex == -1) {\n                    // Assign the last index. This covers the case where r is very close to sum.\n                    nextCenterIndex = dx2.length - 1;\n                }\n            }\n\n\n            // Ensure the chosen index is valid (it should be, given the logic and checks)\n            // and remove the point from the candidate set, adding it to the results.\n             if (nextCenterIndex >= 0 && nextCenterIndex < pointSet.size()) {\n                 final T p = pointSet.remove(nextCenterIndex);\n                 resultSet.add(new Cluster<T>(p));\n             } else {\n                 // This state should theoretically not be reached if pointSet was not empty\n                 // and the logic above is sound. Break defensively.\n                 // Log.warn(\"Could not select next center index, breaking K-means++ loop.\"); // If logger available\n                 break;\n             }\n        }\n\n        return resultSet;\n    }\n\n    /**\n     * Helper method to find the nearest cluster. Assumed to exist in the original class or context.\n     *\n     * @param <T> type of the points to cluster\n     * @param clusters the existing clusters\n     * @param point the point to find the nearest cluster for\n     * @return the cluster with the nearest center\n     */\n     private static <T extends Clusterable<T>> Cluster<T> getNearestCluster(final Collection<Cluster<T>> clusters, final T point) {\n         double minDistance = Double.POSITIVE_INFINITY;\n         Cluster<T> nearest = null;\n         for (final Cluster<T> cluster : clusters) {\n             final double distance = point.distanceFrom(cluster.getCenter());\n             if (distance < minDistance) {\n                 minDistance = distance;\n                 nearest = cluster;\n             }\n         }\n         return nearest;\n     }\n\n     // --- Mock interfaces/classes needed for the code snippet to compile standalone ---\n     // These should be replaced by the actual definitions from Apache Commons Math\n     interface Clusterable<T> {\n         double distanceFrom(T p);\n         T centroidOf(Collection<T> p); // Example method, may vary\n         int[] getPoint(); // Specific to test case point type\n     }\n\n     static class Cluster<T extends Clusterable<T>> {\n         private T center;\n         private final List<T> points = new ArrayList<T>();\n\n         public Cluster(T center) {\n             this.center = center;\n         }\n\n         public T getCenter() {\n             return center;\n         }\n\n         public void addPoint(T point) {\n             points.add(point);\n         }\n\n         public List<T> getPoints() {\n             return points;\n         }\n     }\n     // --- End Mock interfaces/classes ---",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}