{
    "generation": "import java.nio.ByteBuffer;\nimport java.nio.charset.Charset;\nimport java.nio.charset.IllegalCharsetNameException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.charset.UnsupportedCharsetException;\nimport org.jsoup.helper.Validate;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.parser.Parser;\n\n// Note: This code assumes the existence of a static helper method 'getCharsetFromContentType(String)'\n// and that the class has necessary imports.\n\n    // todo - this is getting gnarly. needs a rewrite.\n    static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData = null;\n        Document doc = null;\n        // Use StandardCharsets.UTF_8 directly, assuming it's the intended default.\n        // Replace with DataUtil.defaultCharset if it's defined differently elsewhere.\n        final Charset defaultCharset = StandardCharsets.UTF_8;\n\n        if (charsetName == null) { // determine from byte data or meta\n            // First, try to decode as UTF-8 to check for BOM and meta tags\n            byteData.mark(); // Mark buffer start in case we need to rewind\n            docData = defaultCharset.decode(byteData).toString();\n\n            // Check for UTF-8 BOM (U+FEFF). http://www.unicode.org/faq/utf_bom.html#BOM\n            if (docData.length() > 0 && docData.charAt(0) == 65279) {\n                // Confirmed UTF-8 BOM, clean the string and parse.\n                charsetName = defaultCharset.name();\n                docData = docData.substring(1); // Remove BOM from string\n                // Buffer was consumed by decode. We parse the string without BOM. No need to reset buffer here.\n                doc = parser.parseInput(docData, baseUri);\n            } else {\n                // No BOM found via initial UTF-8 decode. Need buffer again if meta check requires re-decode.\n                byteData.reset(); // Reset buffer to marked position (start) for potential re-decode\n\n                // Parse the UTF-8 decoded data to find meta tags\n                doc = parser.parseInput(docData, baseUri); // Parse the string we got from initial decode\n                Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n                String foundCharset = null;\n\n                if (meta != null) { // Look for charset in meta tags\n                    if (meta.hasAttr(\"http-equiv\")) {\n                        // getCharsetFromContentType is a static helper, needs to be callable.\n                        foundCharset = getCharsetFromContentType(meta.attr(\"content\"));\n                    }\n                    if (foundCharset == null && meta.hasAttr(\"charset\")) { // If not found, try the charset attribute.\n                        try {\n                            if (Charset.isSupported(meta.attr(\"charset\"))) {\n                                foundCharset = meta.attr(\"charset\");\n                            }\n                        } catch (IllegalCharsetNameException e) {\n                            // ignore unsupported charset name\n                            foundCharset = null;\n                        }\n                    }\n                }\n\n                // If we found a valid different charset, rewind buffer and re-decode\n                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equalsIgnoreCase(defaultCharset.name())) {\n                    foundCharset = foundCharset.trim().replaceAll(\"[\\\"']\", \"\"); // Clean charset name\n                    charsetName = foundCharset; // Update the final charset name\n\n                    try {\n                        // Ensure charset is supported before using. (Defensive)\n                        if (!Charset.isSupported(charsetName))\n                           throw new UnsupportedCharsetException(charsetName);\n\n                        // Re-decode using the found charset. Buffer is at the start due to reset().\n                        docData = Charset.forName(charsetName).decode(byteData).toString();\n                        doc = null; // Discard the initial potentially incorrect parse we did to find meta\n                    } catch (UnsupportedCharsetException | IllegalCharsetNameException e) {\n                        // Declared charset invalid or unsupported. Keep the initial UTF-8 parse.\n                        // doc is already parsed as UTF-8. Set charset name back.\n                        charsetName = defaultCharset.name();\n                        // doc remains the result of the initial parse\n                    }\n                } else { // No meta tag suitable charset found, or meta specified defaultCharset\n                    charsetName = defaultCharset.name();\n                    // doc remains the result of the initial parse\n                }\n            }\n        } else { // Charset specified (e.g., from HTTP header or user)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            // Use the specified charset. Assumes the decoder handles BOMs if relevant for the charset.\n            // Throws UnsupportedCharsetException / IllegalCharsetNameException if invalid.\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n        }\n\n        // If doc is null, it means we had an explicit charset OR the meta-tag search led to a re-decode request.\n        // Parse the docData obtained using the final determined charset.\n        if (doc == null) {\n            // We must have docData from one of the paths above.\n            doc = parser.parseInput(docData, baseUri);\n        }\n\n        // Ensure the document knows its encoding. charsetName should be correctly set now.\n        doc.outputSettings().charset(charsetName);\n        return doc;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}