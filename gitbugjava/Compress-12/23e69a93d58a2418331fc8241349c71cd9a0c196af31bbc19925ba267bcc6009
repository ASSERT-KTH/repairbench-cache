{
    "generation": "    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            long numToSkip = entrySize - entryOffset;\n\n            // Skip the remaining data of the current entry.\n            // Uses the stream's skip method, which should account for record boundaries\n            // if implemented correctly within the TarArchiveInputStream context.\n            while (numToSkip > 0) {\n                long skipped = skip(numToSkip); // Use the stream's skip method\n                if (skipped <= 0) {\n                    // Changed from RuntimeException to IOException for better error handling\n                    throw new IOException(\"Failed to skip remaining data in entry: \" + currEntry.getName());\n                }\n                // Re-calculate numToSkip based on the current offset after skipping\n                numToSkip = entrySize - entryOffset;\n            }\n\n            readBuf = null; // Reset internal buffer used by read()\n        }\n\n        byte[] headerBuf = getRecord(); // Read the next 512-byte header record\n\n        // Check for EOF or end-of-archive marker (all zeros)\n        if (headerBuf == null) {\n            // getRecord() returns null on EOF or serious error\n            hasHitEOF = true;\n        } else if (isEOFRecord(headerBuf)) { // Check if the record is all zeros\n            hasHitEOF = true;\n            // Consume the second TAR EOF record if present and strict parsing is desired\n            // tryToConsumeSecondEOFRecord(); // Placeholder for potentially consuming the second EOF block\n        }\n\n        if (hasHitEOF) {\n            currEntry = null;\n            return null;\n        }\n\n        try {\n            // *** FIX START ***\n            // Parse the header buffer. This operation can throw IllegalArgumentException\n            // if the header contains invalid data (e.g., non-octal characters in numeric fields).\n            currEntry = new TarArchiveEntry(headerBuf);\n            // *** FIX END ***\n        } catch (IllegalArgumentException e) {\n            // Wrap the IllegalArgumentException in an IOException as expected by callers\n            // and indicated by test case testCOMPRESS178.\n            IOException ioe = new IOException(\"Error detected parsing the header\");\n            ioe.initCause(e); // Set the original parsing error as the cause\n            throw ioe;\n        }\n\n        // Reset the entry offset for the new entry\n        entryOffset = 0;\n        // Get the size of the entry from the newly parsed header\n        entrySize = currEntry.getSize();\n\n        // Handle GNU long name entries ('././@LongLink')\n        if (currEntry.isGNULongNameEntry()) {\n            // The entry data contains the actual long name, null-terminated.\n            // Read the name data exactly entrySize bytes long.\n            StringBuffer longName = new StringBuffer();\n            // Using a buffer for reading; SMALL_BUFFER_SIZE is likely 256 or 512\n            byte[] buf = new byte[SMALL_BUFFER_SIZE];\n            int length = 0;\n            long bytesToRead = entrySize;\n            while (bytesToRead > 0) {\n                 // Use the stream's read method, ensuring it handles stream positioning and entry limits\n                length = read(buf, 0, (int) Math.min(buf.length, bytesToRead));\n                if (length < 0) { // Check for unexpected EOF\n                     throw new IOException(\"Unexpected EOF while reading GNU long name data\");\n                }\n                if (length == 0 && bytesToRead > 0) {\n                    // Safeguard against streams that might return 0 without EOF\n                    throw new IOException(\"Read returned 0 bytes without EOF while reading GNU long name data\");\n                }\n                // Append the read bytes, assuming appropriate encoding (often ASCII/UTF-8 for GNU)\n                // Note: new String(byte[]) uses default charset, which might be incorrect.\n                // TarUtils or TarEncodingHelper should ideally be used for correct decoding.\n                longName.append(new String(buf, 0, length /*, charset? */));\n                // Update remaining bytes based on how much was actually read (entryOffset should be updated by read)\n                bytesToRead = entrySize - entryOffset;\n             }\n\n            // The stream should now be positioned at the header of the *next* entry.\n            // The original code's recursive call here is problematic and deviates from tar standard processing.\n            // A correct implementation reads the next header *after* the long name data.\n            // For minimal change, we retain the original recursive structure:\n            getNextEntry(); // Recursive call to process the *actual* file entry header\n            if (currEntry == null) {\n                // This handles the case where the long name entry is the last thing in the archive,\n                // or if the subsequent getNextEntry() call returns null. (Bugzilla: 40334)\n                return null;\n            }\n            // Remove trailing null terminator from the long name if present\n            if (longName.length() > 0\n                && longName.charAt(longName.length() - 1) == 0) { // Check NUL character\n                longName.deleteCharAt(longName.length() - 1);\n            }\n            // Apply the retrieved long name to the entry that was just loaded by the recursive call\n            currEntry.setName(longName.toString());\n            // Update size and offset based on the actual entry loaded by recursion\n            entrySize = currEntry.getSize();\n            entryOffset = 0; // Ensure offset is reset for the actual entry\n        }\n\n        // Handle PAX headers (sparse headers are subtypes of PAX headers)\n        if (currEntry.isPaxHeader()){ // Process PAX headers ('x' or 'g' typeflag)\n            paxHeaders(); // Assumes this method reads the PAX data, processes it, reads the next header, and updates currEntry\n            if (currEntry == null) { // paxHeaders might have hit EOF or an error\n                return null;\n            }\n            // PAX headers can change entry attributes like size, so update entrySize and reset offset\n            entrySize = currEntry.getSize();\n            entryOffset = 0;\n        }\n\n        // Handle GNU sparse files ('S' typeflag)\n        // Note: PAX sparse format is handled within paxHeaders() typically\n        if (currEntry.isGNUSparse()){ // Process GNU sparse file headers\n            readGNUSparse(); // Assumes this method reads sparse map, reads next header, and updates currEntry\n            if (currEntry == null) { // readGNUSparse might have hit EOF or an error\n                 return null;\n            }\n            // Sparse headers might affect effective size or processing, ensure state is correct\n            entrySize = currEntry.getSize(); // Update size (might be overall size including holes)\n            entryOffset = 0; // Reset offset\n        }\n\n        // Final update of entrySize, ensuring it reflects the value from the\n        // potentially modified currEntry after handling extensions (PAX/Sparse).\n        // This might be redundant if handled correctly within paxHeaders/readGNUSparse.\n        entrySize = currEntry.getSize();\n\n        return currEntry;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}