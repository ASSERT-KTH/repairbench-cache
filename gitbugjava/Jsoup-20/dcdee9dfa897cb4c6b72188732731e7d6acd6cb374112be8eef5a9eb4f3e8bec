{
    "generation": "import org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.helper.Validate;\n\nimport java.nio.ByteBuffer;\nimport java.nio.charset.Charset;\nimport java.nio.charset.UnsupportedCharsetException;\n// Assuming context provides defaultCharset and getCharsetFromContentType\n// e.g., private static final String defaultCharset = \"UTF-8\";\n// e.g., private static String getCharsetFromContentType(String contentType) { ... }\n\n    // switching the chartset midstream when a meta http-equiv tag defines the charset.\n    static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        boolean charsetDetermined = false; // Flag if we have confidence in the charset\n        final String originalCharsetName = charsetName; // Keep original for comparison checks & meta skip\n\n        if (originalCharsetName == null) { // determine from meta. safe parse as UTF-8\n            // First pass: Decode with defaultCharset, check for meta tags\n            try {\n                byteData.mark(); // Mark buffer position in case we need to rewind\n                docData = Charset.forName(defaultCharset).decode(byteData).toString();\n                byteData.reset(); // Rewind buffer after decode for potential re-read with found charset\n            } catch (UnsupportedCharsetException e) {\n                // Should not happen as defaultCharset is validated in DataUtil static initialiser.\n                throw new RuntimeException(e);\n            }\n\n            // Provisional parse to find meta\n            doc = parser.parseInput(docData, baseUri);\n            // Selectors evolved over jsoup versions; using original simple selector logic:\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n\n            if (meta != null) {\n                String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n                if (foundCharset != null && foundCharset.length() != 0) {\n                    // Validate the found charset\n                    try {\n                        Charset.forName(foundCharset); // Check if supported\n                        // If it's different from default, mark for re-decode\n                        // Charset names are case-insensitive -> use equalsIgnoreCase\n                        if (!foundCharset.equalsIgnoreCase(defaultCharset)) {\n                            charsetName = foundCharset;\n                            charsetDetermined = true; // We found a specific charset\n                            doc = null; // Discard provisional parse, need to re-decode\n                        } else {\n                            // It's the same as default, use the provisional parse\n                            charsetName = defaultCharset;\n                            charsetDetermined = true; // Confident it's defaultCharset\n                        }\n                    } catch (UnsupportedCharsetException e) {\n                        // Found charset but unsupported, stick with defaultCharset and provisional parse\n                        charsetName = defaultCharset;\n                        charsetDetermined = false; // Not confident, using fallback\n                        // Keep the provisional doc parsed with defaultCharset\n                    }\n                } else {\n                    // Meta found but charset attribute is empty or invalid, stick with defaultCharset and provisional parse\n                    charsetName = defaultCharset;\n                    charsetDetermined = false; // Not confident, using fallback\n                    // Keep the provisional doc parsed with defaultCharset\n                }\n            } else {\n                // No meta found, stick with defaultCharset and provisional parse\n                charsetName = defaultCharset;\n                charsetDetermined = false; // Not confident, using fallback (might be UTF-8, might not)\n                // Keep the provisional doc parsed with defaultCharset\n            }\n\n            // If we need to re-decode (found different supported charset)\n            // Check doc == null implies we need re-decode; charsetDetermined ensures foundCharset is valid\n            if (doc == null && charsetDetermined) {\n                try {\n                    // We already reset the byteData buffer\n                    docData = Charset.forName(charsetName).decode(byteData).toString();\n                } catch (UnsupportedCharsetException e) {\n                     // Should not happen as we already validated with Charset.forName above\n                     throw new RuntimeException(e);\n                }\n            }\n            // Else: use the docData decoded with defaultCharset (and the provisional doc if available)\n\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            try {\n                 // No need to mark/reset here as we won't re-read unless there's an error (which throws)\n                 docData = Charset.forName(charsetName).decode(byteData).toString();\n                 charsetDetermined = true; // User specified it\n            } catch (UnsupportedCharsetException e) {\n                // Let the exception propagate as original code did\n                throw e;\n            }\n            // doc remains null, parse happens below\n        }\n\n        // *** BOM Strip ***\n        // Do this *after* potential re-decode and *before* the final parse\n        // It's safe to modify docData now.\n        // Check for UTF-8 BOM (\\uFEFF)\n        if (docData != null && docData.length() > 0 && docData.charAt(0) == 65279) {\n            docData = docData.substring(1);\n            // If we were going to use the provisional parse (doc != null),\n            // we must discard it and re-parse because the BOM is gone and affects parsing.\n            if (doc != null) {\n                doc = null;\n            }\n        }\n\n        // *** Final Parse ***\n        // If doc is null, we need to parse (because charset was specified, or we re-decoded, or we stripped BOM)\n        if (doc == null) {\n            // We should have valid docData. Charset for parsing is implicitly handled by having correct docData string.\n            if (docData == null) { // Defensive check for hypothetical null docData\n                 docData = \"\"; // prevent NPE in parseInput\n            }\n            doc = parser.parseInput(docData, baseUri);\n        }\n\n        // *** Set Output Charset ***\n        // Use the charset we ended up with.\n        // If detection failed or wasn't attempted, charsetName will hold the effective charset (provided or default).\n        if (charsetName == null) { // Should have been set to default if started as null and detection failed\n             charsetName = defaultCharset;\n        }\n        doc.outputSettings().charset(charsetName);\n\n        return doc;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}