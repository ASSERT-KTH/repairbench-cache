{
    "generation": "import org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.helper.Validate;\n\nimport java.nio.ByteBuffer;\nimport java.nio.charset.Charset;\n// Imports assumed to exist based on context and original code\nimport static org.jsoup.helper.DataUtil.defaultCharset;\nimport static org.jsoup.helper.DataUtil.getCharsetFromContentType;\n\n\nclass FixedDataUtil {\n    // switching the chartset midstream when a meta http-equiv tag defines the charset.\n    static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        String detectedCharset = null; // To store charset detected from meta tag\n\n        if (charsetName == null) { // determine from meta. safe parse as UTF-8\n            // First pass: decode as default charset and look for meta tag\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            doc = parser.parseInput(docData, baseUri); // Preliminary parse\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            if (meta != null) { // if not found, will keep utf-8 as best attempt\n                // get charset attribute from meta[charset] or meta[http-equiv=content-type]\n                String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode. (case insensitive check handled by equals defaultCharset)\n                    // found a different charset, store it\n                    detectedCharset = foundCharset;\n                }\n            }\n\n            // If we found a different charset, re-decode and re-parse\n            if (detectedCharset != null) {\n                // clean up the found charset\n                detectedCharset = detectedCharset.trim().replaceAll(\"[\\\"']\", \"\");\n                // let's verify it's supported:\n                if (Charset.isSupported(detectedCharset)) {\n                    charsetName = detectedCharset; // use the detected charset for the second pass\n                    byteData.rewind();\n                    docData = Charset.forName(charsetName).decode(byteData).toString();\n                    doc = null; // discard preliminary parse result, need to reparse\n                } else {\n                    // unsupported charset detected; keep the preliminary parse statistical best-guess\n                    // but ensure the charsetName variable reflects the actual charset used (default)\n                    charsetName = defaultCharset;\n                    // doc is potentially valid from the first parse, but check for BOM if default was UTF-8\n                    if (doc != null && docData.length() > 0 && docData.charAt(0) == 65279) { // check for UTF-8 BOM\n                        // BOM detected, need to strip and reparse\n                        docData = docData.substring(1);\n                        doc = null;\n                    }\n                }\n            } else {\n                // No different charset detected, use the default charset parse.\n                charsetName = defaultCharset; // Record the charset used\n                // docData is from default charset decode. doc has preliminary parse.\n                // Check for BOM if default was UTF-8.\n                if (doc != null && docData.length() > 0 && docData.charAt(0) == 65279) { // check for UTF-8 BOM\n                    // BOM detected, need to strip and reparse\n                    docData = docData.substring(1);\n                    doc = null;\n                }\n                 // if no BOM, the preliminary doc is the one we want.\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n            // doc is null, will be parsed below\n        }\n\n        if (doc == null) {\n            // If doc is null, we need to parse docData.\n            // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n            // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n            // into head mode\n            if (docData.length() > 0 && docData.charAt(0) == 65279) { // check for UTF-8 BOM (\\uFEFF)\n                docData = docData.substring(1);\n            }\n\n            doc = parser.parseInput(docData, baseUri);\n\n            // set charset on document output settings\n            // charsetName should hold the name of the charset used to decode the data by this point\n            Validate.notNull(charsetName, \"Charaset name should not be null here\");\n            doc.outputSettings().charset(charsetName);\n        }\n        // If doc was not null (because we used the preliminary parse with default charset and no BOM),\n        // ensure its output charset is set correctly.\n        else {\n             doc.outputSettings().charset(charsetName);\n        }\n        return doc;\n    }\n}",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}