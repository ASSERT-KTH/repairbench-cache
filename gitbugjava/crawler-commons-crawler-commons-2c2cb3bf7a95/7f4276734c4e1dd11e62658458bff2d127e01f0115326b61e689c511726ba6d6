{
    "generation": "private SimpleRobotRules parseContent(String url, byte[] content, String contentType, Collection<String> robotNames, boolean exactUserAgentMatching) {\n\n    // If there's nothing there, treat it like we have no restrictions.\n    if ((content == null) || (content.length == 0)) {\n        return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n    }\n\n    int bytesLen = content.length;\n    int offset = 0;\n    Charset encoding = StandardCharsets.US_ASCII;\n\n    // Check for BOMs first\n    // UTF-8 BOM (EF BB BF)\n    if ((bytesLen >= 3) && content[0] == (byte)0xEF && content[1]== (byte)0xBB && content[2] == (byte)0xBF) {\n        offset =3;\n        bytesLen -=3;\n        encoding = StandardCharsets.UTF_8;\n    // UTF-16LE BOM (FF FE)\n    } else if (bytesLen >=2 && content[0]==(byte)0xFF && content[1]==(byte)0xFE) {\n        offset=2;\n        bytesLen -=2;\n        encoding = StandardCharsets.UTF_16LE;\n    // UTF-16BE BOM (FE FF)\n    } else if (bytesLen >=2 && content[0]==(byte)0xFE && content[1]==(byte)0xFF) {\n        offset=2;\n        bytesLen -=2;\n        encoding = StandardCharsets.UTF_16BE;\n    }\n\n    // Now check content-type's charset if BOM not found\n    if (offset == 0 && contentType != null) {\n        final String lower = contentType.toLowerCase(Locale.ROOT);\n        final int charsetPos = lower.indexOf(\"charset=\");\n        if (charsetPos != -1) {\n            int eqPos = contentType.indexOf('=', charsetPos);\n            if (eqPos != -1) {\n                eqPos +=1;\n                int semiPos = contentType.indexOf(';', eqPos);\n                int end = (semiPos == -1) ? contentType.length() : semiPos;\n                String charset = contentType.substring(eqPos, end).trim();\n                // Remove quotes if any\n                if (charset.startsWith(\"\\\"\") && charset.endsWith(\"\\\"\")) {\n                    charset = charset.substring(1, charset.length()-1);\n                } else if (charset.startsWith(\"'\") && charset.endsWith(\"'\")) {\n                    charset = charset.substring(1, charset.length()-1);\n                }\n                try {\n                    encoding = Charset.forName(charset);\n                } catch (Exception e) {\n                    // Handle unsupported or invalid charset by retaining the encoding\n                    LOGGER.trace(\"Invalid charset '{}' specified in robots.txt content type: using default (US_ASCII) for {}\",\n                                charset, url);\n                }\n            }\n        }\n    }\n\n    // Now convert the remaining bytes using the determined encoding\n    String contentAsStr = new String(content, offset, bytesLen, encoding);\n\n    // ... resto del c\u00f3digo original (HTML processing, line parsing, etc.) sigue sin cambios\n    // Decide if HTML processing is needed\n    boolean isHtmlType = ((contentType != null) && contentType.toLowerCase(Locale.ROOT).startsWith(\"text/html\"));\n\n    // Check for HTML content presence\n    boolean hasHTML = false;\n    if (isHtmlType || SIMPLE_HTML_PATTERN.matcher(contentAsStr).find()) {\n        if (!USER_AGENT_PATTERN.matcher(contentAsStr).find()) {\n            LOGGER.trace(\"Found non-robots.txt HTML file: \" + url);\n            return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n        } else {\n            log if necessary\n            hasHTML = true;\n            // ... (rest of the logic continues as before)\n        }\n    }\n\n    // Existing code for line parsing remains unchanged here and below\n    StringTokenizer lineParser = new StringTokenizer(contentAsStr, \"\\n\\r\\u0085\\u2028\\u2029\");\n    ParseState parseState = new ParseState(url, robotNames);\n\n    while (lineParser.hasMoreTokens()) {\n        // ... (existing line processing logic continues)\n    }\n\n    // ... (remainder of the method remains unchanged regarding the Crawl-Delay check and returning rules)\n    this._numWarningsDuringLastParse.set(parseState._numWarnings);\n    SimpleRobotRules result = parseState.getRobotRules();\n    if (result.getCrawlDelay() > _maxCrawlDelay) {\n        // ... (existing code for exceeding crawl delay)\n    } else {\n        result.sortRules();\n        return result;\n    }\n}",
    "exact_match": false,
    "ast_match": false,
    "compile": null,
    "test": false
}