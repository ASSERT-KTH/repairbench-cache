{
    "generation": "private SimpleRobotRules parseContent(String url, byte[] content, String contentType,\n                                      Collection<String> robotNames,\n                                      boolean exactUserAgentMatching) {\n\n    // If there's nothing there, treat it like we have no restrictions.\n    if ((content == null) || (content.length == 0)) {\n        return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n    }\n\n    int bytesLen = content.length;\n    int offset = 0;\n    // Default to UTF-8 (instead of US_ASCII) so unescaped Unicode is handled correctly.\n    Charset encoding = StandardCharsets.UTF_8;\n\n    // Check for a UTF-8 BOM at the beginning (EF BB BF)\n    if ((bytesLen >= 3)\n        && (content[0] == (byte) 0xEF)\n        && (content[1] == (byte) 0xBB)\n        && (content[2] == (byte) 0xBF)) {\n        offset = 3;\n        bytesLen -= 3;\n        encoding = StandardCharsets.UTF_8;\n    }\n    // Check for UTF-16LE BOM at the beginning (FF FE)\n    else if ((bytesLen >= 2)\n             && (content[0] == (byte) 0xFF)\n             && (content[1] == (byte) 0xFE)) {\n        offset = 2;\n        bytesLen -= 2;\n        encoding = StandardCharsets.UTF_16LE;\n    }\n    // Check for UTF-16BE BOM at the beginning (FE FF)\n    else if ((bytesLen >= 2)\n             && (content[0] == (byte) 0xFE)\n             && (content[1] == (byte) 0xFF)) {\n        offset = 2;\n        bytesLen -= 2;\n        encoding = StandardCharsets.UTF_16BE;\n    }\n\n    String contentAsStr = new String(content, offset, bytesLen, encoding);\n\n    // Decide if we need to do special HTML processing.\n    boolean isHtmlType = ((contentType != null)\n                          && contentType.toLowerCase(Locale.ROOT).startsWith(\"text/html\"));\n    boolean hasHTML = false;\n    if (isHtmlType || SIMPLE_HTML_PATTERN.matcher(contentAsStr).find()) {\n        if (!USER_AGENT_PATTERN.matcher(contentAsStr).find()) {\n            LOGGER.trace(\"Found non-robots.txt HTML file: \" + url);\n            return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n        } else {\n            if (isHtmlType) {\n                LOGGER.debug(\"HTML content type returned for robots.txt file: \" + url);\n            } else {\n                LOGGER.debug(\"Found HTML in robots.txt file: \" + url);\n            }\n            hasHTML = true;\n        }\n    }\n\n    // Break on anything that might be used as a line ending.\n    StringTokenizer lineParser = new StringTokenizer(\n        contentAsStr, \"\\n\\r\\u0085\\u2028\\u2029\");\n    ParseState parseState = new ParseState(url, robotNames);\n\n    while (lineParser.hasMoreTokens()) {\n        String line = lineParser.nextToken();\n        if (hasHTML) {\n            line = line.replaceAll(\"<[^>]+>\", \"\");\n        }\n        int hashPos = line.indexOf(\"#\");\n        if (hashPos >= 0) {\n            line = line.substring(0, hashPos);\n        }\n        line = line.trim();\n        if (line.isEmpty()) {\n            continue;\n        }\n\n        RobotToken token = tokenize(line);\n        switch (token.getDirective()) {\n            case USER_AGENT:\n                handleUserAgent(parseState, token);\n                break;\n\n            case DISALLOW:\n                parseState.setFinishedAgentFields(true);\n                handleDisallow(parseState, token);\n                // --- normalization for Unicode <-> percent-encoded paths ---\n                String pathVal = token.getValue();\n                // 1) decode any percent-encoded UTF-8 to Unicode\n                try {\n                    String decoded = java.net.URLDecoder.decode(\n                        pathVal, StandardCharsets.UTF_8.name());\n                    if (!decoded.equals(pathVal)) {\n                        RobotToken dt = tokenize(\n                            token.getDirective().name() + \": \" + decoded);\n                        handleDisallow(parseState, dt);\n                    }\n                } catch (IllegalArgumentException | java.io.UnsupportedEncodingException e) {\n                    // ignore invalid escape sequences\n                }\n                // 2) percent-encode any non-ASCII characters\n                StringBuilder sb = new StringBuilder();\n                for (int i = 0; i < pathVal.length(); ) {\n                    int cp = pathVal.codePointAt(i);\n                    if (cp <= 0x7F) {\n                        sb.append((char) cp);\n                    } else {\n                        byte[] bytes = new String(Character.toChars(cp))\n                                            .getBytes(StandardCharsets.UTF_8);\n                        for (byte b : bytes) {\n                            sb.append('%');\n                            char h1 = Character.toUpperCase(\n                                Character.forDigit((b >> 4) & 0xF, 16));\n                            char h2 = Character.toUpperCase(\n                                Character.forDigit(b & 0xF, 16));\n                            sb.append(h1).append(h2);\n                        }\n                    }\n                    i += Character.charCount(cp);\n                }\n                String encoded = sb.toString();\n                if (!encoded.equals(pathVal)) {\n                    RobotToken et = tokenize(\n                        token.getDirective().name() + \": \" + encoded);\n                    handleDisallow(parseState, et);\n                }\n                break;\n\n            case ALLOW:\n                parseState.setFinishedAgentFields(true);\n                handleAllow(parseState, token);\n                // --- same normalization for ALLOW ---\n                String pathValA = token.getValue();\n                try {\n                    String decodedA = java.net.URLDecoder.decode(\n                        pathValA, StandardCharsets.UTF_8.name());\n                    if (!decodedA.equals(pathValA)) {\n                        RobotToken dtA = tokenize(\n                            token.getDirective().name() + \": \" + decodedA);\n                        handleAllow(parseState, dtA);\n                    }\n                } catch (IllegalArgumentException | java.io.UnsupportedEncodingException e) {\n                    // ignore\n                }\n                StringBuilder sbA = new StringBuilder();\n                for (int i = 0; i < pathValA.length(); ) {\n                    int cp = pathValA.codePointAt(i);\n                    if (cp <= 0x7F) {\n                        sbA.append((char) cp);\n                    } else {\n                        byte[] bytes = new String(Character.toChars(cp))\n                                            .getBytes(StandardCharsets.UTF_8);\n                        for (byte b : bytes) {\n                            sbA.append('%');\n                            char h1 = Character.toUpperCase(\n                                Character.forDigit((b >> 4) & 0xF, 16));\n                            char h2 = Character.toUpperCase(\n                                Character.forDigit(b & 0xF, 16));\n                            sbA.append(h1).append(h2);\n                        }\n                    }\n                    i += Character.charCount(cp);\n                }\n                String encodedA = sbA.toString();\n                if (!encodedA.equals(pathValA)) {\n                    RobotToken etA = tokenize(\n                        token.getDirective().name() + \": \" + encodedA);\n                    handleAllow(parseState, etA);\n                }\n                break;\n\n            case CRAWL_DELAY:\n                parseState.setFinishedAgentFields(true);\n                handleCrawlDelay(parseState, token);\n                break;\n\n            case SITEMAP:\n                parseState.setFinishedAgentFields(true);\n                handleSitemap(parseState, token);\n                break;\n\n            case HTTP:\n                parseState.setFinishedAgentFields(true);\n                handleHttp(parseState, token);\n                break;\n\n            case UNKNOWN:\n                reportWarning(parseState,\n                    \"Unknown directive in robots.txt file: {}\", line);\n                parseState.setFinishedAgentFields(true);\n                break;\n\n            case MISSING:\n                reportWarning(parseState,\n                    \"Unknown line in robots.txt file (size {}): {}\",\n                    content.length, line);\n                parseState.setFinishedAgentFields(true);\n                break;\n\n            default:\n                // ignore others\n                break;\n        }\n    }\n\n    this._numWarningsDuringLastParse.set(parseState._numWarnings);\n    SimpleRobotRules result = parseState.getRobotRules();\n    if (result.getCrawlDelay() > _maxCrawlDelay) {\n        LOGGER.debug(\n            \"Crawl delay exceeds max value - so disallowing all URLs: {}\",\n            url);\n        return new SimpleRobotRules(RobotRulesMode.ALLOW_NONE);\n    } else {\n        result.sortRules();\n        return result;\n    }\n}",
    "exact_match": false,
    "ast_match": false,
    "compile": null,
    "test": false
}