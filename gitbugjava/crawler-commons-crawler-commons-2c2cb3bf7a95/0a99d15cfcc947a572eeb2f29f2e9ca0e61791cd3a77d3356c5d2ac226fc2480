{
    "generation": "    private SimpleRobotRules parseContent(String url, byte[] content, String contentType, Collection<String> robotNames, boolean exactUserAgentMatching) {\n\n        // If there's nothing there, treat it like we have no restrictions.\n        if ((content == null) || (content.length == 0)) {\n            return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n        }\n\n        int bytesLen = content.length;\n        int offset = 0;\n        Charset encoding = StandardCharsets.UTF_8; // Default to UTF-8 per spec\n\n        // Check for BOMs and override encoding if present\n        boolean hasBOM = false;\n        // Check for a UTF-8 BOM at the beginning (EF BB BF)\n        if ((bytesLen >= 3) && (content[0] == (byte) 0xEF) && (content[1] == (byte) 0xBB) && (content[2] == (byte) 0xBF)) {\n            offset = 3;\n            bytesLen -= 3;\n            encoding = StandardCharsets.UTF_8;\n            hasBOM = true;\n        }\n        // Check for UTF-16LE BOM at the beginning (FF FE)\n        else if ((bytesLen >= 2) && (content[0] == (byte) 0xFF) && (content[1] == (byte) 0xFE)) {\n            offset = 2;\n            bytesLen -= 2;\n            encoding = StandardCharsets.UTF_16LE;\n            hasBOM = true;\n        }\n        // Check for UTF-16BE BOM at the beginning (FE FF)\n        else if ((bytesLen >= 2) && (content[0] == (byte) 0xFE) && (content[1] == (byte) 0xFF)) {\n            offset = 2;\n            bytesLen -= 2;\n            encoding = StandardCharsets.UTF_16BE;\n            hasBOM = true;\n        }\n\n        // If no BOM found, check Content-Type for charset\n        if (!hasBOM && contentType != null) {\n            String[] parts = contentType.split(\";\\\\s*\");\n            for (String part : parts) {\n                if (part.toLowerCase(Locale.ROOT).startsWith(\"charset=\")) {\n                    String charsetName = part.substring(\"charset=\".length()).trim();\n                    charsetName = charsetName.replaceAll(\"^['\\\"]|['\\\"]$\", \"\");\n                    try {\n                        encoding = Charset.forName(charsetName);\n                    } catch (IllegalCharsetNameException | UnsupportedCharsetException e) {\n                        LOGGER.debug(\"Unsupported charset in content-type: {}\", charsetName);\n                    }\n                    break;\n                }\n            }\n        }\n\n        String contentAsStr = new String(content, offset, bytesLen, encoding);\n\n        // Decide if we need to do special HTML processing.\n        boolean isHtmlType = ((contentType != null) && contentType.toLowerCase(Locale.ROOT).startsWith(\"text/html\"));\n\n        // Check if content is HTML without user-agent field\n        boolean hasHTML = false;\n        if (isHtmlType || SIMPLE_HTML_PATTERN.matcher(contentAsStr).find()) {\n            if (!USER_AGENT_PATTERN.matcher(contentAsStr).find()) {\n                LOGGER.trace(\"Found non-robots.txt HTML file: \" + url);\n                return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n            } else {\n                LOGGER.debug((isHtmlType ? \"HTML content type returned for robots.txt file: \" : \"Found HTML in robots.txt file: \") + url);\n                hasHTML = true;\n            }\n        }\n\n        StringTokenizer lineParser = new StringTokenizer(contentAsStr, \"\\n\\r\\u0085\\u2028\\u2029\");\n        ParseState parseState = new ParseState(url, robotNames);\n\n        while (lineParser.hasMoreTokens()) {\n            String line = lineParser.nextToken();\n\n            if (hasHTML) {\n                line = line.replaceAll(\"<[^>]+>\", \"\");\n            }\n\n            // Trim comments and whitespace\n            int hashPos = line.indexOf(\"#\");\n            if (hashPos >= 0) {\n                line = line.substring(0, hashPos);\n            }\n            line = line.trim();\n            if (line.isEmpty()) {\n                continue;\n            }\n\n            RobotToken token = tokenize(line);\n            try {\n                switch (token.getDirective()) {\n                    case USER_AGENT:\n                        handleUserAgent(parseState, token);\n                        break;\n\n                    case DISALLOW:\n                        parseState.setFinishedAgentFields(true);\n                        handleDisallow(parseState, decodeTokenValue(token));\n                        break;\n\n                    case ALLOW:\n                        parseState.setFinishedAgentFields(true);\n                        handleAllow(parseState, decodeTokenValue(token));\n                        break;\n\n                    case CRAWL_DELAY:\n                        parseState.setFinishedAgentFields(true);\n                        handleCrawlDelay(parseState, token);\n                        break;\n\n                    case SITEMAP:\n                        parseState.setFinishedAgentFields(true);\n                        handleSitemap(parseState, token);\n                        break;\n\n                    case HTTP:\n                        parseState.setFinishedAgentFields(true);\n                        handleHttp(parseState, token);\n                        break;\n\n                    case UNKNOWN:\n                        reportWarning(parseState, \"Unknown directive in robots.txt file: {}\", line);\n                        parseState.setFinishedAgentFields(true);\n                        break;\n\n                    case MISSING:\n                        reportWarning(parseState, \"Unknown line in robots.txt file (size {}): {}\", content.length, line);\n                        parseState.setFinishedAgentFields(true);\n                        break;\n\n                    default:\n                        // Ignore other directives\n                        break;\n                }\n            } catch (Exception e) {\n                reportWarning(parseState, \"Error processing line: {}\", line);\n            }\n        }\n\n        this._numWarningsDuringLastParse.set(parseState._numWarnings);\n        SimpleRobotRules result = parseState.getRobotRules();\n        if (result.getCrawlDelay() > _maxCrawlDelay) {\n            LOGGER.debug(\"Crawl delay exceeds max value - disallowing all URLs: {}\", url);\n            return new SimpleRobotRules(RobotRulesMode.ALLOW_NONE);\n        } else {\n            result.sortRules();\n            return result;\n        }\n    }\n\n    private RobotToken decodeTokenValue(RobotToken token) {\n        try {\n            String decodedValue = URLDecoder.decode(token.getValue(), StandardCharsets.UTF_8.name());\n            return new RobotToken(token.getDirective(), decodedValue);\n        } catch (UnsupportedEncodingException e) {\n            // Should not happen with UTF-8\n            return token;\n        } catch (IllegalArgumentException e) {\n            // Invalid percent encoding, return original token\n            return token;\n        }\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": null,
    "test": false
}