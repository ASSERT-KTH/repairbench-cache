{
    "generation": "private SimpleRobotRules parseContent(String url, byte[] content, String contentType, Collection<String> robotNames, boolean exactUserAgentMatching) {\n\n    // If there's nothing there, treat it like we have no restrictions.\n    if ((content == null) || (content.length == 0)) {\n        return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n    }\n\n    int bytesLen = content.length;\n    int offset = 0;\n    Charset encoding = StandardCharsets.US_ASCII;\n\n    // Check for a UTF-8 BOM at the beginning (EF BB BF)\n    if ((bytesLen >= 3) && (content[0] == (byte) 0xEF) && (content[1] == (byte) 0xBB) && (content[2] == (byte) 0xBF)) {\n        offset = 3;\n        bytesLen -= 3;\n        encoding = StandardCharsets.UTF_8;\n    }\n    // Check for UTF-16LE BOM (FF FE)\n    else if ((bytesLen >= 2) && (content[0] == (byte) 0xFF) && (content[1] == (byte) 0xFE)) {\n        offset = 2;\n        bytesLen -= 2;\n        encoding = StandardCharsets.UTF_16LE;\n    }\n    // Check for UTF-16BE BOM (FE FF)\n    else if ((bytesLen >= 2) && (content[0] == (byte) 0xFE) && (content[1] == (byte) 0xFF)) {\n        offset = 2;\n        bytesLen -= 2;\n        encoding = StandardCharsets.UTF_16BE;\n    }\n\n    // Check Content-Type's charset if no BOM detected\n    if (encoding == StandardCharsets.US_ASCII) {\n        String charsetName = null;\n        if (contentType != null) {\n            for (String param : contentType.split(\";\")) {\n                param = param.trim();\n                int eqIndex = param.indexOf('=');\n                if (eqIndex != -1) {\n                    String key = param.substring(0, eqIndex).trim().toLowerCase(Locale.ROOT);\n                    if (\"charset\".equals(key)) {\n                        charsetName = param.substring(eqIndex + 1).trim();\n                        break;\n                    }\n                }\n            }\n        }\n        if (charsetName != null) {\n            try {\n                encoding = Charset.forName(charsetName);\n            } catch (Exception e) {\n                // Log and continue with US-ASCII if charset invalid/unsupported\n                LOGGER.debug(\"Invalid/unavailable charset ({}) for {}: defaulting to US-ASCII\", charsetName, url);\n                encoding = StandardCharsets.US_ASCII;\n            }\n        }\n    }\n\n    String contentAsStr = new String(content, offset, bytesLen, encoding);\n\n    // Decide if HTML content type may need processing\n    boolean isHtmlType = ((contentType != null) && contentType.toLowerCase(Locale.ROOT).startsWith(\"text/html\"));\n    boolean hasHTML = false;\n\n    // Check for HTML content type or embedded HTML patterns\n    if (isHtmlType || SIMPLE_HTML_PATTERN.matcher(contentAsStr).find()) {\n        if (!USER_AGENT_PATTERN.matcher(contentAsStr).find()) {\n            LOGGER.trace(\"Found non-robots.txt HTML file: \" + url);\n            return new SimpleRobotRules(RobotRulesMode.ALLOW_ALL);\n        }\n        hasHTML = true;\n        if (!isHtmlType) {\n            LOGGER.debug(\"Found HTML in robots.txt file: \" + url);\n        }\n        if (isHtmlType) {\n            LOGGER.debug(\"HTML content type returned for robots.txt file: \" + url);\n        }\n    }\n\n    StringTokenizer lineParser = new StringTokenizer(contentAsStr, \"\\n\\r\\u0085\\u2028\\u2029\");\n    ParseState parseState = new ParseState(url, robotNames);\n\n    while (lineParser.hasMoreTokens()) {\n        String line = lineParser.nextToken();\n\n        if (hasHTML) line = line.replaceAll(\"<[^>]+>\", \"\");\n\n        int hashPos = line.indexOf(\"#\");\n        if (hashPos >= 0) line = line.substring(0, hashPos).trim();\n\n        line = line.trim();\n        if (line.length() == 0) continue;\n\n        RobotToken token = tokenize(line);\n        switch (token.getDirective()) {\n            case USER_AGENT:\n                handleUserAgent(parseState, token);\n                break;\n            case DISALLOW:\n                parseState.setFinishedAgentFields(true);\n                handleDisallow(parseState, token);\n                break;\n            case ALLOW:\n                parseState.setFinishedAgentFields(true);\n                handleAllow(parseState, token);\n                break;\n            case CRAWL_DELAY:\n                parseState.setFinishedAgentFields(true);\n                handleCrawlDelay(parseState, token);\n                break;\n            case SITEMAP:\n                parseState.setFinishedAgentFields(true);\n                handleSitemap(parseState, token);\n                break;\n            case HTTP:\n                parseState.setFinishedAgentFields(true);\n                handleHttp(parseState, token);\n                break;\n            case UNKNOWN:\n                reportWarning(parseState, \"Unknown directive: {}\", line);\n                parseState.setFinishedAgentFields(true);\n                break;\n            case MISSING:\n                reportWarning(parseState, \"Malformed line: possibility invalid directive: {}\", line);\n                parseState.setFinishedAgentFields(true);\n                break;\n            default:\n                break;\n        }\n    }\n\n    this._numWarningsDuringLastParse.set(parseState._numWarnings);\n\n    SimpleRobotRules result = parseState.getRobotRules();\n    if (result.getCrawlDelay() > _maxCrawlDelay) {\n        LOGGER.warn(\"Crawl delay ({}) exceeds maximum allowed for: {}, defaulting to disallow all\", result.getCrawlDelay(), url);\n        return new SimpleRobotRules(RobotRulesMode.DISALLOW_ALL);\n    } else {\n        result.sortRules();\n        return result;\n    }\n}",
    "exact_match": false,
    "ast_match": false,
    "compile": null,
    "test": false
}