{
    "generation": "import org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.helper.Validate; // Assuming Validate is in this package or imported\n\nimport java.nio.ByteBuffer;\nimport java.nio.charset.Charset;\nimport java.nio.charset.IllegalCharsetNameException;\n\n// Assume other necessary imports and class structure exist\n\n/**\n * Parses the input byte data into a Document. Switches to preferred charset if specified, otherwise detects appropriately.\n *\n * @param byteData    Bytes to parse. Be sure the buffer is rewound or the position is at the start.\n * @param charsetName Character set to decode bytes into. If null, attempts to detect from byte order mark or meta tag.\n * @param baseUri     The URL where the document was fetched from (for resolving relative links).\n * @param parser      The parser to use.\n * @return Document parsed from the byte data.\n */\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData = null;\n    Document doc = null;\n    String foundCharset = null; // Charset found from BOM or meta tag\n    // Use the standard UTF-8 name. Avoid Charset.defaultCharset() which can be locale-dependent and might not be UTF-8.\n    final String defaultCharset = \"UTF-8\";\n\n    // ****** BOM Detection START ******\n    // Determines the character set from the stream byte order mark if present, and advances the buffer position past it.\n    // See http://www.unicode.org/faq/utf_bom.html#BOM\n    byteData.mark(); // Mark position before reading BOM\n    byte[] bom = new byte[4];\n    int bomLen = 0; // Number of bytes consumed by BOM\n\n    // Must have at least 2 bytes to check for any BOM\n    if (byteData.remaining() >= 2) {\n        int read = Math.min(byteData.remaining(), 4);\n        byteData.get(bom, 0, read);\n        byteData.reset(); // Reset position to start for decoding later if no BOM found or for re-reading after BOM\n\n        // Check BOM patterns (order matters: check longer BOMs first)\n        if (read >= 4 && bom[0] == (byte) 0x00 && bom[1] == (byte) 0x00 && bom[2] == (byte) 0xFE && bom[3] == (byte) 0xFF) { // UTF-32BE\n            foundCharset = \"UTF-32BE\";\n            bomLen = 4;\n        } else if (read >= 4 && bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE && bom[2] == (byte) 0x00 && bom[3] == (byte) 0x00) { // UTF-32LE\n            foundCharset = \"UTF-32LE\";\n            bomLen = 4;\n        } else if (read >= 3 && bom[0] == (byte) 0xEF && bom[1] == (byte) 0xBB && bom[2] == (byte) 0xBF) { // UTF-8\n            foundCharset = \"UTF-8\";\n            bomLen = 3;\n        } else if (read >= 2 && bom[0] == (byte) 0xFE && bom[1] == (byte) 0xFF) { // UTF-16BE\n            foundCharset = \"UTF-16BE\";\n            bomLen = 2;\n        } else if (read >= 2 && bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE) { // UTF-16LE\n            foundCharset = \"UTF-16LE\";\n            bomLen = 2;\n        }\n\n        if (foundCharset != null) {\n            // Advance the position past the BOM\n            byteData.position(byteData.position() + bomLen);\n        }\n        // If no BOM found, position remains at the start due to reset()\n    }\n    // ****** BOM Detection END ******\n\n    if (foundCharset != null) {\n        // BOM determines charset. Use it. Ignore caller's charset for decoding.\n        charsetName = foundCharset;\n        // Decode the remaining data (after BOM is skipped)\n        docData = Charset.forName(foundCharset).decode(byteData).toString();\n    } else if (charsetName == null) { // No BOM, no charset specified by caller: detect from meta.\n        // We need to parse the start of the doc to look for meta tags.\n        // Decode tentatively using the default UTF-8. If we find a meta tag with a different charset, re-decode.\n        byteData.mark(); // Mark position before decoding for potential rewind\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n\n        // Look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        // Use the lenient parser for meta tag detection - don't require closing tags, etc.\n        Document earlyDoc = parser.parseInput(docData, baseUri); // Temporary parse\n        Element meta = earlyDoc.selectFirst(\"meta[http-equiv=content-type], meta[charset]\");\n\n        if (meta != null) { // Found a meta tag\n            String metaCharset = null;\n            if (meta.hasAttr(\"http-equiv\")) {\n                // Example: <meta http-equiv=\"Content-Type\" content=\"text/html; charset=EUC-KR\">\n                metaCharset = getCharsetFromContentType(meta.attr(\"content\"));\n                // getCharsetFromContentType handles parsing \"text/html; charset=UTF-8\" and returns the charset part\n            }\n            if (metaCharset == null && meta.hasAttr(\"charset\")) {\n                // Example: <meta charset=\"UTF-8\">\n                metaCharset = meta.attr(\"charset\");\n            }\n\n            if (metaCharset != null && metaCharset.length() > 0 && !metaCharset.equalsIgnoreCase(defaultCharset)) {\n                // Found a different charset, need to re-decode. Clean and check support.\n                String cleanedCharset = metaCharset.trim().replaceAll(\"[\\\"']\", \"\"); // Remove quotes, trim whitespace\n                try {\n                    if (Charset.isSupported(cleanedCharset)) {\n                        // Charset is supported, use it\n                        charsetName = cleanedCharset;\n                        byteData.reset(); // Rewind buffer to read bytes again with the correct charset\n                        docData = Charset.forName(charsetName).decode(byteData).toString();\n                        // Let doc be null so the main parse below happens with the new docData\n                    } else {\n                        // Unsupported charset in meta tag, stick with default initial parse\n                        charsetName = defaultCharset;\n                        doc = earlyDoc; // Use the doc parsed with default charset\n                    }\n                } catch (IllegalCharsetNameException e) {\n                    // Treat as unsupported if name is illegal (should be caught by isSupported, but belt & braces)\n                    charsetName = defaultCharset;\n                    doc = earlyDoc; // Use the doc parsed with default charset\n                }\n            } else {\n                // Meta tag found, but charset is same as default, empty, or null. Stick with default initial parse.\n                charsetName = defaultCharset;\n                doc = earlyDoc; // Use the doc parsed with default charset\n            }\n        } else {\n            // No meta tag found, stick with default initial parse.\n            charsetName = defaultCharset;\n            doc = earlyDoc; // Use the doc parsed with default charset\n        }\n    } else { // No BOM found, but charset was specified by caller. Use it.\n        // Should not be empty string as checked by caller, but be defensive.\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n        // doc remains null, needs parsing. charsetName is already set by caller.\n    }\n\n    // The old BOM check based on decoded string starting with \\uFEFF is removed as BOM is handled at byte level now.\n\n    if (doc == null) {\n        // We need to parse:\n        // 1. BOM detected & docData decoded.\n        // 2. No BOM, null charset -> meta tag required re-decode & docData re-decoded.\n        // 3. No BOM, caller specified charset & docData decoded.\n\n        // Ensure docData is not null (could happen if byteData was empty). Guard against NPE in parser.\n        if (docData == null) {\n             // If byteData was empty or failed decoding, use empty string\n             docData = \"\";\n        }\n\n        // Parse the string data obtained from the correctly detected/specified charset.\n        doc = parser.parseInput(docData, baseUri);\n\n        // Ensure the document's output settings reflect the determined charset.\n        // If charsetName ended up null (shouldn't happen with this logic), default to UTF-8.\n        doc.outputSettings().charset(charsetName != null ? charsetName : defaultCharset);\n\n    } else {\n        // We don't need to parse again. Doc was created during meta check, using default charset.\n        // Ensure the output charset is set correctly (should be defaultCharset in this path).\n        doc.outputSettings().charset(defaultCharset);\n    }\n    return doc;\n}\n\n// Assume helper method exists elsewhere in the class:\n// static String getCharsetFromContentType(String contentType) { ... }",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}