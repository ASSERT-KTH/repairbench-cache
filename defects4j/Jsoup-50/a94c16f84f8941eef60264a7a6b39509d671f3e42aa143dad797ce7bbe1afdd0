{
    "generation": "import org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.helper.Validate;\n\nimport java.nio.ByteBuffer;\nimport java.nio.charset.Charset;\nimport java.nio.charset.IllegalCharsetNameException;\n\n// Assuming the following are accessible within the class context:\n// - A static final String defaultCharset = \"UTF-8\"; (or similar default)\n// - A static method String getCharsetFromContentType(String contentType) { ... }\n\n/**\n * Parses the input byte data into a Document. If you know the charset, pass it in, otherwise it will be detected appropriately.\n * This utilizes a Byte Order Mark, or falls back to {@code <meta charset>} or {@code <meta http-equiv=\"Content-Type\">}.\n *\n * @param byteData    bytes to parse\n * @param charsetName character set of input; specify {@code null} to attempt to autodetect. A BOM in the data will always override this setting.\n * @param baseUri     base URI of document, to resolve relative links against\n * @param parser      fluent parser to use when parsing content\n * @return Document parsed from the byte data.\n */\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData = null;\n    Document doc = null;\n    String foundCharset = null; // Charset determined by BOM, override, or meta\n\n    // Determine the character set. Priority: BOM > override (charsetName) > meta tag > default (UTF-8)\n\n    // 1. Check for BOM. The data buffer position will be advanced past the BOM if found.\n    byteData.mark();\n    final int UNSET = -1; // Use local constants for byte values to avoid magic numbers\n    final int B1 = 0, B2 = 1, B3 = 2, B4 = 3;\n    int[] b = {UNSET, UNSET, UNSET, UNSET};\n    // Read up to 4 bytes for BOM detection, handle buffer underflow\n    for (int i = 0; i < 4 && byteData.hasRemaining(); i++) {\n        b[i] = byteData.get() & 0xFF; // Read byte and convert to unsigned int\n    }\n    byteData.reset(); // Reset position after reading bytes for check\n\n    // Now check the read bytes (b array) for BOM patterns\n    if (b[B1] == 0x00 && b[B2] == 0x00 && b[B3] == 0xFE && b[B4] == 0xFF) {       // UTF-32BE (00 00 FE FF)\n        foundCharset = \"UTF-32BE\"; byteData.position(byteData.position() + 4);\n    } else if (b[B1] == 0xFF && b[B2] == 0xFE && b[B3] == 0x00 && b[B4] == 0x00) { // UTF-32LE (FF FE 00 00)\n        foundCharset = \"UTF-32LE\"; byteData.position(byteData.position() + 4);\n    } else if (b[B1] == 0xFE && b[B2] == 0xFF) {                                  // UTF-16BE (FE FF)\n        foundCharset = \"UTF-16BE\"; byteData.position(byteData.position() + 2);\n    } else if (b[B1] == 0xFF && b[B2] == 0xFE) {                                  // UTF-16LE (FF FE)\n        foundCharset = \"UTF-16LE\"; byteData.position(byteData.position() + 2);\n    } else if (b[B1] == 0xEF && b[B2] == 0xBB && b[B3] == 0xBF) {                 // UTF-8 (EF BB BF)\n        foundCharset = \"UTF-8\";    byteData.position(byteData.position() + 3);\n    }\n    // If no BOM found, foundCharset remains null, and position is still at the original mark (due to reset).\n\n    if (foundCharset == null && charsetName != null) {\n        // 2. No BOM, but charset provided externally (override)\n        // Note: If charsetName is null, this is skipped, and we proceed to meta-detect.\n        foundCharset = charsetName;\n    }\n\n    if (foundCharset == null) { // 3. No BOM, no external charset -> detect from meta or use default\n        // We need to decode the start of the document with a default charset to find meta tags.\n        // Mark the position so we can rewind if we need to re-decode with a different charset.\n        byteData.mark();\n        try {\n            // Decode using the default charset\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            // Parse tentatively to find meta tags\n            doc = parser.parseInput(docData, baseUri);\n            // Look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\">\n            // or HTML5 <meta charset=\"gb2312\">\n            Element meta = doc.selectFirst(\"meta[http-equiv=content-type], meta[charset]\");\n            String metaCharset = null;\n\n            if (meta != null) {\n                if (meta.hasAttr(\"http-equiv\")) {\n                    metaCharset = getCharsetFromContentType(meta.attr(\"content\"));\n                }\n                if (metaCharset == null && meta.hasAttr(\"charset\")) {\n                    try {\n                        // Check if the charset is supported before using it\n                        if (Charset.isSupported(meta.attr(\"charset\"))) {\n                            metaCharset = meta.attr(\"charset\");\n                        }\n                    } catch (IllegalCharsetNameException e) {\n                        // Ignore invalid charset names in meta tags\n                        metaCharset = null;\n                    }\n                }\n            }\n\n            // Handle found meta charset. Must be non-blank and different from default to trigger re-decode.\n            if (metaCharset != null && metaCharset.length() != 0 && !metaCharset.equalsIgnoreCase(defaultCharset)) {\n                // Meta tag found a different charset. Clean and assign it.\n                metaCharset = metaCharset.trim().replaceAll(\"[\\\"']\", \"\");\n                foundCharset = metaCharset;\n                doc = null; // Set doc back to null to re-parse after re-decoding\n\n                // Rewind the byte buffer to the marked position and decode with the correct charset.\n                byteData.reset();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n            } else {\n                 // No meta charset found, or it matched the default. Use the default charset.\n                 // The initial parse ('doc') remains valid, and the buffer is already consumed by the first decode.\n                 foundCharset = defaultCharset;\n            }\n        } catch (Exception e) {\n            // Handle exceptions during the tentative decode/parse for meta detection.\n            // For robustness, might fallback to default charset or rethrow. Rethrowing for now.\n            // Consider logging the error.\n            throw new RuntimeException(\"Exception during charset detection: \" + e.getMessage(), e);\n        }\n    } else { // 4. BOM found or external charset provided\n        // Decode using the charset determined by BOM or override.\n        // Validate foundCharset is not null, though logic implies it cannot be here.\n        Validate.notNull(foundCharset);\n        // If BOM was found, buffer position was advanced. If override was used, position is at start.\n        // decode() consumes the buffer from the current position.\n        docData = Charset.forName(foundCharset).decode(byteData).toString();\n    }\n\n    if (doc == null) {\n        // If doc is null, it needs parsing. This happens if:\n        // - We decoded using BOM or override charset (case 4).\n        // - We re-decoded based on a meta tag finding (case 3, meta differs).\n        // If doc is not null, it means we used the default charset and found no different meta tag (case 3, meta matches or not found).\n        // We need docData to parse. It should have been set correctly in the relevant logic path.\n        if (docData == null) {\n             // This should ideally not happen if decode throws or returns empty string for empty input.\n             // Defensively handle potential null docData.\n             docData = \"\";\n        }\n        doc = parser.parseInput(docData, baseUri);\n    }\n\n    // Set the finally determined charset on the document's output settings.\n    // foundCharset might be null if the input was empty and no charset could be determined.\n    if (foundCharset != null) {\n        doc.outputSettings().charset(foundCharset);\n    }\n    return doc;\n}",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}