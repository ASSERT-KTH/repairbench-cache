{
    "generation": "import org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.helper.Validate;\nimport java.nio.ByteBuffer;\nimport java.nio.charset.Charset;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\n// NOTE: This code snippet includes necessary imports and stubs for helper methods/constants\n//       that were likely present in the original `DataUtil` class but not provided in the prompt.\n//       The core logic fix is within the `parseByteData` method itself.\n\nclass DataUtilStub { // Helper stub to make the function compile standalone\n    static final String defaultCharset = \"UTF-8\"; // Assuming UTF-8 default\n\n    // Stub for the helper method, assuming it extracts charset from Content-Type string\n    static String getCharsetFromContentType(String contentType) {\n        if (contentType == null) return null;\n        // Simplified example regex, original might be more robust\n        Pattern pattern = Pattern.compile(\"(?i)\\\\bcharset=\\\\s*\\\"?([^\\\\s;\\\"]*)\");\n        Matcher matcher = pattern.matcher(contentType);\n        if (matcher.find()) {\n            return matcher.group(1).trim().toUpperCase();\n        }\n        return null;\n    }\n\n    // The fixed function:\n    /**\n     * Parses the input byte data into a Document. If charsetName is not provided, uses the default charset\n     * (UTF-8), and then reads the file to find a meta charset tag. If found, and the charset is different,\n     * restarts the parse with the new charset. If none found, uses the default.\n     * <p>Assumes the input stream {@code byteData} has a usable {@code mark} available.</p>\n     *\n     * @param byteData    byte data to parse. Must be rewindable (e.g. a ByteBuffer).\n     * @param charsetName character set of input; specify {@code null} to attempt to autodetect. A BOM in the data will be discarded.\n     * @param baseUri     The URL where the HTML was retrieved from, to resolve relative links against.\n     * @param parser      alternate parser to use.\n     * @return parsed Document\n     */\n    static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        String finalCharset = charsetName; // Track the final charset used\n\n        // *** Bugfix: Need to use mark/reset on the buffer to allow multi-decodes if auto-detecting. ***\n        byteData.mark();\n\n        if (finalCharset == null) { // determine from meta. safe parse first as UTF-8\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            finalCharset = defaultCharset; // Assume default initially\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(finalCharset, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(finalCharset).decode(byteData).toString();\n        }\n\n        // Check for BOM and strip if present. See http://www.unicode.org/faq/utf_bom.html#BOM\n        // Note this check runs against the decoded string, not the raw bytes - if the specific charset doesn't preserve the BOM, might not be detected\n        if (docData.length() > 0 && docData.charAt(0) == '\\uFEFF') {\n            docData = docData.substring(1);\n        }\n\n        // If charset wasn't specified (detection mode)\n        if (charsetName == null) {\n            // We need to parse the head to look for meta tags\n            // This parse is done on the data decoded using defaultCharset (potentially BOM-stripped)\n            // Create a temporary document for meta tag detection\n            // TODO: potentially use lower-level scanning instead of fully parsing twice.\n            Document earlyDoc = parser.parseInput(docData, baseUri);\n            Element meta = earlyDoc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            String foundCharset = null;\n\n            if (meta != null) { // found meta tag\n                if (meta.hasAttr(\"http-equiv\")) {\n                    foundCharset = getCharsetFromContentType(meta.attr(\"content\"));\n                    // ensure charset utf-8 properly specified like http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"\n                    if (foundCharset == null && meta.attr(\"content\").toLowerCase().contains(\"charset=\")) {\n                         foundCharset = getCharsetFromContentType(\"charset=\" + meta.attr(\"content\").substring(meta.attr(\"content\").indexOf(\"charset=\") + 8));\n                    }\n                }\n                if (foundCharset == null && meta.hasAttr(\"charset\")) {\n                    foundCharset = meta.attr(\"charset\");\n                }\n            }\n\n\n            if (foundCharset != null && foundCharset.length() > 0 && !foundCharset.equalsIgnoreCase(defaultCharset)) {\n                // Found a different charset, need to re-decode.\n                foundCharset = foundCharset.trim().replaceAll(\"[\\\"']\", \"\"); // clean charset name\n                finalCharset = foundCharset; // Update the final charset\n\n                // Rewind the original buffer and re-decode with the correct charset\n                byteData.reset(); // Rewind to marked position\n                docData = Charset.forName(finalCharset).decode(byteData).toString();\n\n                // Strip BOM again if present after re-decoding with correct charset\n                if (docData.length() > 0 && docData.charAt(0) == '\\uFEFF') {\n                    docData = docData.substring(1);\n                }\n                // Need to parse again with the correct content\n                doc = null; // Makes sure we parse again below\n            } else {\n                // No charset change needed, use the initially parsed doc\n                doc = earlyDoc;\n                // finalCharset remains defaultCharset as initially set\n            }\n        }\n\n        // If doc is null, parse the docData (which is now finalized with the correct charset and BOM-stripped)\n        if (doc == null) {\n            // docData could be null if byteData is empty, parser should handle, ensure no NPE here\n             if (docData == null) docData = \"\"; // Should not happen with Charset decoders normally\n            doc = parser.parseInput(docData, baseUri);\n        }\n\n        // Set the charset on the final document\n        // Validate finalCharset is not null, should always have default or specified/detected\n        Validate.notNull(finalCharset);\n        doc.outputSettings().charset(finalCharset);\n\n        return doc;\n    }\n}\n",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}