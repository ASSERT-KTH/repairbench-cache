{
    "generation": "    // switching the chartset midstream when a meta http-equiv tag defines the charset.\n    static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        final char BOM = '\\uFEFF'; // Byte Order Mark\n\n        if (charsetName == null) { // determine from meta. safe parse as UTF-8\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n\n            // Check for BOM, remove it before initial parse. Hitting this is potentially unexpected,\n            // as BOMs are usually specific to UTF-16/UTF-32, but better check + strip if present.\n            if (docData.length() > 0 && docData.charAt(0) == BOM) {\n                docData = docData.substring(1);\n            }\n\n            doc = parser.parseInput(docData, baseUri); // Initial parse\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            String foundCharset = null;\n            if (meta != null) { // if not found, will keep utf-8 as best attempt\n                 foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            }\n\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equalsIgnoreCase(defaultCharset)) { // need to re-decode. (use equalsIgnoreCase)\n                charsetName = foundCharset; // Update track charset name\n                byteData.rewind(); // Rewind buffer for re-decode\n                docData = Charset.forName(foundCharset).decode(byteData).toString(); // Decode again with found charset\n\n                // Check for BOM again after re-decode\n                if (docData.length() > 0 && docData.charAt(0) == BOM) {\n                    docData = docData.substring(1);\n                }\n                doc = null; // Signal re-parse is needed\n            } else {\n                // No useful charset found in meta, stick with initial parse doc and default charset\n                charsetName = defaultCharset; // Use the default charset name\n                // doc is the initial parse result\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n            // Check for BOM, remove it. Relevant for UTF-8 BOMs etc detected after decode.\n            if (docData.length() > 0 && docData.charAt(0) == BOM) {\n                docData = docData.substring(1);\n            }\n            // doc remains null, parse needed\n        }\n\n        if (doc == null) { // If parse is needed (because charset specified, or detected different charset requiring re-decode)\n            // docData should now be clean (BOM-stripped if needed) and decoded with the correct charset\n            doc = parser.parseInput(docData, baseUri);\n            // charsetName will be non-null here: either the provided one, or the found one, or the default after detection failure/match.\n        }\n\n        // Set the document's output charset to the definitively used one\n        doc.outputSettings().charset(charsetName);\n        return doc;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": true,
    "test": true
}