{
    "generation": "import java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\nimport org.apache.commons.compress.archivers.zip.ZipShort;\nimport org.apache.commons.compress.archivers.zip.ZipUtil;\n\n// Stub classes and constants needed for compilation\nclass ZipFile {\n    // Assuming these constants exist and have appropriate values\n    static final int SHORT = 2;\n    static final int LFH_OFFSET_FOR_FILENAME_LENGTH = 26;\n\n    // Assuming these fields exist\n    Map<ZipArchiveEntry, OffsetEntry> entries;\n    Map<String, ZipArchiveEntry> nameMap;\n    java.io.RandomAccessFile archive;\n\n    // Placeholder for OffsetEntry internal class or structure\n    static class OffsetEntry {\n        long headerOffset;\n        long dataOffset;\n    }\n\n    // Placeholder for NameAndComment internal class or structure\n    static class NameAndComment {\n        byte[] name;\n        byte[] comment;\n    }\n\n    /**\n     * Walks through all recorded entries and adds the data available\n     * from the local file header.\n     *\n     * <p>Also records the offsets for the data to read from the\n     * entries.</p>\n     */\n    private void resolveLocalFileHeaderData(Map<ZipArchiveEntry, NameAndComment>\n                                            entriesWithoutUTF8Flag)\n        throws IOException {\n        // Map needs to be reconstructed because changing the name of a ZipArchiveEntry\n        // changes its hashCode, potentially breaking the map (COMPRESS-164).\n        // Use a LinkedHashMap to preserve the central directory order.\n        Map<ZipArchiveEntry, OffsetEntry> newEntries =\n            new LinkedHashMap<>(entries.size()); // Initialize with expected size\n\n        // Iterate over a copy of the keySet to ensure we iterate\n        // using the original keys before any potential hashcode changes.\n        for (ZipArchiveEntry ze : new ArrayList<>(entries.keySet())) { // Use copy of keys\n            OffsetEntry offsetEntry = entries.get(ze); // Get OffsetEntry using original key\n            // If ze is not found in entries, something is very wrong.\n            if (offsetEntry == null) {\n                 // This indicates an internal inconsistency. Throw an exception.\n                 throw new IOException(\"Internal error: Entry '\" + ze.getName()\n                                      + \"' not found in offset map during LFH processing.\");\n            }\n\n            long offset = offsetEntry.headerOffset;\n            // Seek to the LFH section containing filename length and extra field length.\n            archive.seek(offset + LFH_OFFSET_FOR_FILENAME_LENGTH);\n            byte[] shortBuf = new byte[SHORT]; // Reuse buffer\n            archive.readFully(shortBuf);\n            int fileNameLen = ZipShort.getValue(shortBuf);\n            archive.readFully(shortBuf);\n            int extraFieldLen = ZipShort.getValue(shortBuf);\n\n            // Skip the filename in the LFH.\n            int lenToSkip = fileNameLen;\n            while (lenToSkip > 0) {\n                int skipped = archive.skipBytes(lenToSkip);\n                if (skipped <= 0) {\n                    // Added entry name to error message for better diagnostics\n                    throw new IOException(\"Failed to skip file name in local file header for entry '\"\n                                               + ze.getName() + \"'\");\n                }\n                lenToSkip -= skipped;\n            }\n\n            // Read the local extra field data.\n            byte[] localExtraData = new byte[extraFieldLen];\n            archive.readFully(localExtraData);\n            // Set the local extra data. Note: This does NOT change the hash code yet.\n            // The ZipArchiveEntry internally stores both local and central extra data.\n            // Parsing logic later (e.g., in getExtraFields(true)) handles merging.\n            ze.setExtra(localExtraData);\n\n            // Calculate the data offset (start of compressed data).\n            // Offset = start of LFH + LFH static size + filename length + extra field length\n            offsetEntry.dataOffset = offset + LFH_OFFSET_FOR_FILENAME_LENGTH // Offset to lengths\n                + SHORT // filename length field size\n                + SHORT // extra field length field size\n                + fileNameLen // actual filename length\n                + extraFieldLen; // actual extra field length\n\n            // If the entry might not have the UTF-8 flag set but needs UTF-8 decoding\n            // (based on central directory info), attempt to find name/comment in extra fields.\n            // We look up using 'ze' which still has its original hashcode at this point.\n            if (entriesWithoutUTF8Flag.containsKey(ze)) {\n                String origName = ze.getName(); // Store original name\n                NameAndComment nc = entriesWithoutUTF8Flag.get(ze); // Get data prepared earlier\n                // This method might change ze.getName() by parsing extra fields,\n                // which in turn changes its hash code.\n                ZipUtil.setNameAndCommentFromExtraFields(ze, nc.name, nc.comment);\n\n                // If the name was changed by the above call, update the nameMap accordingly.\n                if (!origName.equals(ze.getName())) {\n                    nameMap.remove(origName);\n                    nameMap.put(ze.getName(), ze);\n                }\n            }\n\n            // Add the entry (potentially with a new hash code) and its offset data\n            // to the new map.\n            newEntries.put(ze, offsetEntry);\n        }\n\n        // Replace the old map with the newly constructed map.\n        // This ensures lookups using the potentially updated entry objects (with new hashcodes)\n        // will work correctly later, e.g. in getInputStream().\n        if (entries.size() != newEntries.size()) {\n             // Sanity check - should not happen if loop logic is correct\n             throw new IOException(\"Internal error: Entry map size changed unexpectedly during LFH processing.\");\n        }\n        entries.clear();\n        entries.putAll(newEntries);\n    }\n}",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}