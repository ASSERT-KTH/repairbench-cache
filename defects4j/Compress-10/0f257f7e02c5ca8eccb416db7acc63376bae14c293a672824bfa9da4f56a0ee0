{
    "generation": "    /**\n     * Walks through all recorded entries and adds the data available\n     * from the local file header.\n     *\n     * <p>Also records the offsets for the data to read from the\n     * entries.</p>\n     */\n    private void resolveLocalFileHeaderData(Map<ZipArchiveEntry, NameAndComment>\n                                            entriesWithoutUTF8Flag)\n        throws IOException {\n        // changing the name of a ZipArchiveEntry is going to change\n        // the hashcode - see COMPRESS-164\n        // Map needs to be reconstructed in order to keep central\n        // directory order\n\n        // Create new maps to rebuild them with potentially updated ZipArchiveEntry\n        // instances (whose names/hashcodes might have changed).\n        // This ensures map consistency, as modifying a key's hashCode while it's\n        // in the map can lead to lost entries.\n        Map<ZipArchiveEntry, OffsetEntry> newEntries = new LinkedHashMap<>(entries.size());\n        Map<String, ZipArchiveEntry> newNameMap = new LinkedHashMap<>(nameMap.size());\n\n        // Iterate over the original entries map's entry set to preserve order\n        // and safely access keys/values without concurrent modification issues.\n        for (Map.Entry<ZipArchiveEntry, OffsetEntry> entryPair : entries.entrySet()) {\n            ZipArchiveEntry ze = entryPair.getKey(); // The ZipArchiveEntry instance\n            OffsetEntry offsetEntry = entryPair.getValue(); // The associated OffsetEntry\n\n            long offset = offsetEntry.headerOffset;\n            archive.seek(offset + LFH_OFFSET_FOR_FILENAME_LENGTH);\n            byte[] b = new byte[SHORT];\n            archive.readFully(b);\n            int fileNameLen = ZipShort.getValue(b);\n            archive.readFully(b);\n            int extraFieldLen = ZipShort.getValue(b);\n            int lenToSkip = fileNameLen;\n            while (lenToSkip > 0) {\n                int skipped = archive.skipBytes(lenToSkip);\n                if (skipped <= 0) {\n                    throw new RuntimeException(\"failed to skip file name in\"\n                                               + \" local file header\");\n                }\n                lenToSkip -= skipped;\n            }\n            byte[] localExtraData = new byte[extraFieldLen];\n            archive.readFully(localExtraData);\n\n            // Set extra fields from the local file header. This modifies 'ze'.\n            ze.setExtra(localExtraData);\n\n            // Calculate the data offset for the entry.\n            offsetEntry.dataOffset = offset + LFH_OFFSET_FOR_FILENAME_LENGTH\n                + SHORT + SHORT + fileNameLen + extraFieldLen;\n\n            // Store the original name before potential modification\n            String origName = ze.getName();\n\n            // If the entry's UTF8 flag wasn't set in local file header,\n            // try to resolve name/comment from extra fields (e.g., Unicode extra field).\n            // The 'ze' here is the same instance as in entriesWithoutUTF8Flag,\n            // so containsKey/get is safe at this point.\n            if (entriesWithoutUTF8Flag.containsKey(ze)) {\n                NameAndComment nc = entriesWithoutUTF8Flag.get(ze);\n                ZipUtil.setNameAndCommentFromExtraFields(ze, nc.name, nc.comment);\n            }\n\n            // After potential name modification, put the (possibly modified) 'ze'\n            // into the new maps. This ensures hash codes are correctly calculated\n            // based on the final name.\n            newEntries.put(ze, offsetEntry);\n            newNameMap.put(ze.getName(), ze);\n        }\n\n        // Replace the old maps with the new, rebuilt ones.\n        this.entries = newEntries;\n        this.nameMap = newNameMap;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}