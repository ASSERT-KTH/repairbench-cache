{
    "generation": "    /**\n     * Get the next entry in this tar archive. This will skip\n     * over any remaining data in the current entry, if there\n     * is one, and place the input stream at the header of the\n     * next entry, and read the header and instantiate a new\n     * TarEntry from the header bytes and return that entry.\n     * If there are no more entries in the archive, null will\n     * be returned to indicate that the end of the archive has\n     * been reached.\n     *\n     * @return The next TarEntry in the archive, or null.\n     * @throws IOException on error\n     */\n    public TarArchiveEntry getNextTarEntry() throws IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n\n        if (currEntry != null) {\n            long numToSkip = entrySize - entryOffset;\n\n            // Skip loop, using skip method of the ArchiveInputStream\n            // Change RuntimeException to IOException for consistency\n            while (numToSkip > 0) {\n                long skipped = skip(numToSkip);\n                if (skipped <= 0) {\n                    throw new IOException(\"Failed to skip remaining data in tar entry: \"\n                                            + currEntry.getName());\n                }\n                numToSkip -= skipped;\n            }\n\n            readBuf = null;\n        }\n\n        // Read the next 512 byte record.\n        // getRecord() should handle Basic I/O errors and EOF detection.\n        // It may return a buffer of all NULs for the EOF marker.\n        // It should set hasHitEOF appropriately.\n        byte[] headerBuf = getRecord();\n\n        // Check for EOF: getRecord() returns null or sets hasHitEOF.\n        // Also handle TAR EOF marker (two consecutive NUL blocks).\n        if (headerBuf == null) {\n            // If getRecord returns null, we are at EOF.\n            hasHitEOF = true; // Ensure flag is set\n            currEntry = null;\n            return null;\n        }\n        \n        // If getRecord returned a buffer but hasHitEOF is true, treat as EOF\n        // (Might happen with truncated files or errors during getRecord).\n        if(hasHitEOF) {\n            currEntry = null;\n            return null;\n        }\n\n        // Check if the record is the first NUL block of the EOF marker.\n        boolean allZeros = true;\n        for (final byte b : headerBuf) {\n            if (b != 0) {\n                allZeros = false;\n                break;\n            }\n        }\n        if (allZeros) {\n            // This is the first NUL block. TAR requires two.\n            hasHitEOF = true; // Mark EOF conceptually\n            // Consume the second NUL block to leave stream at the proper end.\n            // We don't need the contents, just read past it.\n            // Assume getRecord() reads one block at a time.\n            byte[] secondHeaderBuf = getRecord();\n            if (secondHeaderBuf == null) {\n                 // Proper EOF found while reading second NUL block.\n            } // else: We read something other than EOF, but the first NUL block indicates TAR EOF.\n              //       We still treat it as EOF for practical purposes.\n\n            currEntry = null;\n            return null;\n        }\n\n        // Attempt to parse the header record.\n        try {\n            currEntry = new TarArchiveEntry(headerBuf);\n        } catch (IllegalArgumentException e) {\n            // Wrap the parsing exception (e.g., invalid octal) in an IOException\n            // as required by the failing test case (COMPRESS-178).\n            IOException ioe = new IOException(\"Invalid Tar header. Possible data corruption\", e);\n            // ioe.initCause(e); // Modern constructors take cause directly\n            throw ioe;\n        }\n\n        entryOffset = 0;\n        // Get initial size from header. Might be updated by PAX headers.\n        entrySize = currEntry.getSize();\n\n        // Handle GNU long name extension.\n        if (currEntry.isGNULongNameEntry()) {\n            // The data for this entry is the long name. Read it fully.\n            // Assuming entrySize fits in an int, which is reasonable for names.\n            byte[] nameBytes = new byte[(int) entrySize];\n            // Use a utility or loop to ensure all bytes are read.\n            // Using read(nameBytes, 0, nameBytes.length) in a loop or IOUtils.readFully\n            int read = org.apache.commons.compress.utils.IOUtils.readFully(this, nameBytes);\n            if (read != entrySize) {\n                 throw new IOException(\"Unexpected EOF while reading GNU long name data\");\n            }\n\n            // Skip any padding to the next record boundary after the name data.\n            long bytesToSkip = recordSize - (entrySize % recordSize);\n            if (bytesToSkip > 0 && bytesToSkip != recordSize) {\n                 long skipped = skip(bytesToSkip);\n                 if (skipped != bytesToSkip){\n                     throw new IOException(\"Failed to skip padding after GNU long name data\");\n                 }\n            }\n\n            // Store the long name (decode using appropriate helper, remove NUL).\n            // Assume TarEncodingHelper exists and works.\n             String longName = TarEncodingHelper.getINSTANCE().decode(nameBytes);\n             if (longName.length() > 0 && longName.charAt(longName.length() - 1) == 0) {\n                 longName = longName.substring(0, longName.length() - 1);\n             }\n\n            // The *next* record contains the actual header for the file.\n            // Recursively call getNextTarEntry to read and process it.\n            // The recursive call will update currEntry, entrySize, entryOffset.\n            TarArchiveEntry realEntry = getNextTarEntry();\n\n            if (realEntry == null /* currEntry will be null */) {\n                // Handle malformed archive: Long name entry not followed by a real entry.\n                // Maintain original behavior of returning null (Bugzilla 40334).\n                return null;\n            }\n\n            // Apply the long name read earlier to the entry obtained recursively.\n            // currEntry should now refer to the 'realEntry'.\n            currEntry.setName(longName);\n\n            // Return the entry processed by the recursive call.\n            return currEntry;\n        }\n\n        // Handle PAX headers (must happen after potential GNU long name processing).\n        if (currEntry.isPaxHeader()) { // Local PAX header\n            paxHeaders(); // Reads PAX data, updates currEntry fields (like size)\n            // Update local entrySize variable after PAX modifications.\n            entrySize = currEntry.getSize();\n        } else if (currEntry.isGlobalPaxHeader()) { // Global PAX header\n            globalPaxHeaders(); // Reads PAX data, updates global PAX map\n            // A global PAX header isn't a file entry itself. Get the next real entry.\n            return getNextTarEntry(); // Recursive call\n        }\n\n        // Handle GNU sparse file extensions (must happen after PAX modifications).\n        if (currEntry.isGNUSparse()) {\n            readGNUSparse(); // Reads sparse map information from header extensions\n        }\n\n        // Final check: Ensure size is non-negative after potential PAX updates.\n        // Re-read size from entry in case PAX updated it.\n        entrySize = currEntry.getSize();\n        if (entrySize < 0) {\n            throw new IOException(\"Invalid entry size \" + entrySize + \" for entry \"\n                                   + currEntry.getName());\n        }\n\n        return currEntry;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": false,
    "test": false
}