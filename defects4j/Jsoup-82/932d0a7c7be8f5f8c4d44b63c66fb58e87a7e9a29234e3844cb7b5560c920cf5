{
    "generation": "    static Document parseInputStream(InputStream input, String charsetName, String baseUri, Parser parser) throws IOException  {\n        if (input == null)\n            return new Document(baseUri);\n        input = ConstrainableInputStream.wrap(input, bufferSize, 0);\n\n        Document doc = null;\n        boolean fullyRead = false;\n\n        // read the start of the stream and look for a BOM or meta charset\n        input.mark(bufferSize);\n        ByteBuffer firstBytes = readToByteBuffer(input, firstReadBufferSize - 1); // -1 because we read one more to see if completed. First read is < buffer size, so can't be invalid.\n        fullyRead = input.read() == -1;\n        input.reset();\n\n        // look for BOM - overrides any other header or input\n        BomCharset bomCharset = detectCharsetFromBom(firstBytes);\n        if (bomCharset != null)\n            charsetName = bomCharset.charset;\n\n        if (charsetName == null) { // determine from meta. safe first parse as UTF-8\n            String docData = Charset.forName(defaultCharset).decode(firstBytes).toString();\n            doc = parser.parseInput(docData, baseUri);\n\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            Elements metaElements = doc.select(\"meta[http-equiv=content-type], meta[charset]\");\n            String foundCharset = null; // if not found, will keep utf-8 as best attempt\n            for (Element meta : metaElements) {\n                if (meta.hasAttr(\"http-equiv\"))\n                    foundCharset = getCharsetFromContentType(meta.attr(\"content\"));\n                if (foundCharset == null && meta.hasAttr(\"charset\"))\n                    foundCharset = meta.attr(\"charset\");\n                if (foundCharset != null)\n                    break;\n            }\n\n            // look for <?xml encoding='ISO-8859-1'?>\n            if (foundCharset == null && doc.childNodeSize() > 0) {\n                Node first = doc.childNode(0);\n                XmlDeclaration decl = null;\n                if (first instanceof XmlDeclaration)\n                    decl = (XmlDeclaration) first;\n                else if (first instanceof Comment) {\n                    Comment comment = (Comment) first;\n                    if (comment.isXmlDeclaration())\n                        decl = comment.asXmlDeclaration();\n                }\n                if (decl != null) {\n                    if (decl.name().equalsIgnoreCase(\"xml\"))\n                        foundCharset = decl.attr(\"encoding\");\n                }\n            }\n            foundCharset = validateCharset(foundCharset);\n            if (foundCharset != null && !foundCharset.equalsIgnoreCase(defaultCharset)) { // need to re-decode. (case insensitive check here to match how validate works)\n                foundCharset = foundCharset.trim().replaceAll(\"[\\\"']\", \"\");\n                charsetName = foundCharset;\n                doc = null;\n            } else if (!fullyRead) {\n                doc = null;\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        }\n        if (doc == null) {\n            if (charsetName == null)\n                charsetName = defaultCharset;\n            BufferedReader reader = new BufferedReader(new InputStreamReader(input, charsetName), bufferSize);\n            if (bomCharset != null && bomCharset.offset) // creating the buffered reader ignores the input pos, so must skip here\n                reader.skip(1);\n            try {\n                doc = parser.parseInput(reader, baseUri);\n            } catch (UncheckedIOException e) {\n                // io exception when parsing (not seen before because reading the stream as we go)\n                throw e.ioException();\n            }\n\n            // Get the charset that the parser actually used/set in the document's output settings.\n            // Some charsets can read but not encode; if so, switch to an encodable charset (UTF-8)\n            // and update the document's output settings and the meta element itself.\n            Charset currentDocCharset = doc.outputSettings().charset();\n            if (!currentDocCharset.canEncode()) {\n                Charset fallbackCharset = Charset.forName(defaultCharset);\n                doc.outputSettings().charset(fallbackCharset);\n\n                // Find and update the meta charset element in the document to reflect the fallback charset.\n                Elements metaElements = doc.select(\"meta[charset], meta[http-equiv=content-type]\");\n                for (Element meta : metaElements) { // Iterate to find the *first* relevant meta element\n                    if (meta.hasAttr(\"charset\")) {\n                        meta.attr(\"charset\", fallbackCharset.name());\n                        break;\n                    } else if (meta.hasAttr(\"http-equiv\")) {\n                        String content = meta.attr(\"content\");\n                        if (content != null) {\n                            // Replace the charset in \"Content-Type\" attribute if found\n                            String newContent = content.replaceAll(\"(?i)\\\\bcharset=\\\\s*\\\"?([^\\\\s;\\\"]*)\", \"charset=\" + fallbackCharset.name());\n                            meta.attr(\"content\", newContent);\n                            break;\n                        }\n                    }\n                }\n            }\n            // The original line `Charset charset = Charset.forName(charsetName); doc.outputSettings().charset(charset);`\n            // is removed because `doc.outputSettings().charset()` is already set by `parser.parseInput`\n            // and potentially updated above if it was not encodable.\n        }\n        input.close();\n        return doc;\n    }",
    "exact_match": false,
    "ast_match": false,
    "compile": true,
    "test": false
}